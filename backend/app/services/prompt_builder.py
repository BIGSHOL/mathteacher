"""
Dynamic Prompt Builder Service
ì‹œí—˜ì§€ ì»¨í…ìŠ¤íŠ¸ì— ë§ëŠ” ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
"""
from app.db.supabase_client import SupabaseClient
from app.schemas.pattern import (
    BuildPromptRequest,
    BuildPromptResponse,
    ExamContext,
)
from app.services.subject_config import get_subject_config, get_grade_guidelines
# ê³µí†µ ì„¤ì •
from app.services.prompt_config_common import (
    POINTS_VALIDATION_RULES,
    EXAM_SUBJECT_CLASSIFICATION,
    SCHOOL_LEVEL_RULES,
    DIFFICULTY_SYSTEM_FRAMEWORK,
)

# ìˆ˜í•™ ì„¤ì •
from app.services.prompt_config_math import (
    get_topics_for_grade,
    get_mistakes_for_grade,
    get_middle_study_points,
    get_prerequisite_if_high_school,
    SUBJECT_MATCHING_RULES,
    MATH_DIFFICULTY_SYSTEM_4LEVEL as DIFFICULTY_SYSTEM_4LEVEL,
    ESSAY_ANALYSIS_FULL_GUIDE,
)

# ì˜ì–´ ì„¤ì •
from app.services.prompt_config_english import (
    get_english_topics_for_grade,
    get_english_mistakes_for_grade,
    get_english_writing_guide_if_needed,
    get_english_score_level_strategy,
    ENGLISH_DIFFICULTY_SYSTEM_4LEVEL,
    ENGLISH_EVALUATION_SYSTEM,
    ENGLISH_QUESTION_STRATEGIES,
)


class PromptBuilder:
    """ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë”"""

    def __init__(self, db: SupabaseClient):
        self.db = db

    async def build(self, request: BuildPromptRequest) -> BuildPromptResponse:
        """ì‹œí—˜ì§€ ì»¨í…ìŠ¤íŠ¸ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        context = request.exam_context
        used_templates = []
        matched_types = []

        # 1. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        base_prompt = await self._get_base_prompt(context)
        used_templates.append("base")

        # 2. ë¶„ì„ ê°€ì´ë“œë¼ì¸ ìƒì„±
        analysis_guidelines = await self._get_analysis_guidelines(context)

        # 3. ì˜¤ë¥˜ íŒ¨í„´ í”„ë¡¬í”„íŠ¸ (ì„ íƒì )
        error_patterns_prompt = None
        if request.include_error_patterns:
            error_patterns_prompt, matched = await self._get_error_patterns_prompt(context)
            matched_types.extend(matched)

        # 4. ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ (ì„ íƒì )
        examples_prompt = None
        if request.include_examples:
            examples_prompt = await self._get_examples_prompt(
                context,
                max_per_pattern=request.max_examples_per_pattern
            )

        # 5. ì‹œí—˜ì§€ ìœ í˜•ë³„ ì¶”ê°€ ì§€ì‹œì‚¬í•­
        paper_type_instructions = self._get_paper_type_instructions(context)

        # 6. ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°í•©
        combined_prompt = self._combine_prompts(
            base_prompt=base_prompt,
            guidelines=analysis_guidelines,
            error_patterns=error_patterns_prompt,
            examples=examples_prompt,
            paper_type_instructions=paper_type_instructions,
            exam_paper_type=context.exam_paper_type,
            subject=context.subject or "ìˆ˜í•™",
            grade_level=context.grade_level,
            category=context.category,
        )

        return BuildPromptResponse(
            base_prompt=base_prompt,
            analysis_guidelines=analysis_guidelines,
            error_patterns_prompt=error_patterns_prompt,
            examples_prompt=examples_prompt,
            combined_prompt=combined_prompt,
            used_templates=used_templates,
            matched_problem_types=matched_types,
        )

    async def _get_base_prompt(self, context: ExamContext) -> str:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        # DBì—ì„œ ê¸°ë³¸ í…œí”Œë¦¿ ì¡°íšŒ
        result = await self.db.table("prompt_templates").select("*").eq(
            "template_type", "base"
        ).eq(
            "is_active", True
        ).is_(
            "problem_type_id", "null"
        ).order(
            "priority", desc=True
        ).limit(1).execute()

        if result.data and len(result.data) > 0:
            template = result.data[0]
            # í…œí”Œë¦¿ ì‚¬ìš© íšŸìˆ˜ ì¦ê°€
            await self.db.table("prompt_templates").eq("id", template["id"]).update({
                "usage_count": template.get("usage_count", 0) + 1
            }).execute()
            return template["content"]

        # ê¸°ë³¸ í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
        return self._get_default_base_prompt(context)

    def _get_default_base_prompt(self, context: ExamContext) -> str:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (DBì— í…œí”Œë¦¿ì´ ì—†ì„ ë•Œ)"""
        subject = context.subject or "ìˆ˜í•™"
        grade_info = f"í•™ë…„: {context.grade_level}" if context.grade_level else ""
        unit_info = f"ë‹¨ì›: {context.unit}" if context.unit else ""

        # ì„¸ë¶€ ê³¼ëª© ì •ë³´ (ê³µí†µìˆ˜í•™1, ê³µí†µìˆ˜í•™2 ë“±)
        category_info = ""
        if context.category:
            category_info = f"""ì„¸ë¶€ê³¼ëª©: {context.category}
âš ï¸ ì¤‘ìš”: ì´ ì‹œí—˜ì§€ëŠ” [{context.category}] ê³¼ëª©ì…ë‹ˆë‹¤!
- ëª¨ë“  ë¬¸í•­ì˜ topicì„ "{context.category} > ëŒ€ë‹¨ì› > ì†Œë‹¨ì›" í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ë‹¤ë¥¸ ê³¼ëª©(ì˜ˆ: ê³µí†µìˆ˜í•™1)ìœ¼ë¡œ ë¶„ë¥˜í•˜ì§€ ë§ˆì„¸ìš”
- ì˜ˆì‹œ: "{context.category} > ë„í˜•ì˜ ë°©ì •ì‹ > í‰ë©´ì¢Œí‘œ\""""

        # ì¶œì œë²”ìœ„ ì •ë³´ (ë‹¨ì› ëª©ë¡)
        scope_info = ""
        if context.exam_scope and len(context.exam_scope) > 0:
            scope_list = ", ".join(context.exam_scope)
            category_prefix = f"[{context.category}] " if context.category else ""
            scope_info = f"""ì¶œì œë²”ìœ„: {category_prefix}{scope_list}
âš ï¸ ì¤‘ìš”: ë¬¸ì œ ìœ í˜• ë¶„ì„ ì‹œ ì¶œì œë²”ìœ„ì— ëª…ì‹œëœ ë‹¨ì›({scope_list})ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.
- ë²”ìœ„ ì™¸ ë‹¨ì›ìœ¼ë¡œ ë¶„ë¥˜í•˜ì§€ ë§ˆì„¸ìš”
- ê° ë¬¸ì œê°€ ì–´ëŠ ë‹¨ì›ì— ì†í•˜ëŠ”ì§€ ëª…í™•íˆ ë§¤ì¹­í•˜ì„¸ìš”
- ë²”ìœ„ ë‚´ ë‹¨ì›ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, ê°€ì¥ ìœ ì‚¬í•œ ë‹¨ì›ì„ ì„ íƒí•˜ê³  confidenceë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì„¸ìš”"""

        # ê³¼ëª©ë³„ ì „ë¬¸ê°€ ì—­í• 
        expert_roles = {
            "ìˆ˜í•™": "ìˆ˜í•™ ì‹œí—˜ì§€ ë¶„ì„ ì „ë¬¸ê°€",
            "ì˜ì–´": "ì˜ì–´ ì‹œí—˜ì§€ ë¶„ì„ ì „ë¬¸ê°€",
        }
        expert_role = expert_roles.get(subject, f"{subject} ì‹œí—˜ì§€ ë¶„ì„ ì „ë¬¸ê°€")

        return f"""ë‹¹ì‹ ì€ {expert_role}ì…ë‹ˆë‹¤.

## ë¶„ì„ ëŒ€ìƒ ì •ë³´
- ê³¼ëª©: {subject}
{grade_info}
{unit_info}
{category_info}
{scope_info}

## ë¶„ì„ ëª©í‘œ
1. ê° ë¬¸ì œì˜ ìœ í˜•ê³¼ ë‚œì´ë„ íŒŒì•…
2. í•™ìƒ ë‹µì•ˆ ë¶„ì„ (ë‹µì•ˆì´ ìˆëŠ” ê²½ìš°)
3. ì˜¤ë¥˜ íŒ¨í„´ ì‹ë³„ ë° í”¼ë“œë°± ì œê³µ

## ì‘ë‹µ í˜•ì‹
ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""

    async def _get_analysis_guidelines(self, context: ExamContext) -> list[str]:
        """ë¶„ì„ ê°€ì´ë“œë¼ì¸ ê°€ì ¸ì˜¤ê¸°"""
        guidelines = []

        # ì„¸ë¶€ ê³¼ëª© ì œí•œ ê°€ì´ë“œë¼ì¸ (ìµœìµœìš°ì„ !)
        if context.category:
            guidelines.append(f"ğŸš¨ ê³¼ëª© ì œí•œ: ì´ ì‹œí—˜ì§€ëŠ” [{context.category}] ê³¼ëª©ì…ë‹ˆë‹¤!")
            guidelines.append(f"ëª¨ë“  ë¬¸í•­ì˜ topicì„ ë°˜ë“œì‹œ \"{context.category} > ëŒ€ë‹¨ì› > ì†Œë‹¨ì›\" í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.")
            guidelines.append(f"âŒ ë‹¤ë¥¸ ê³¼ëª©(ì˜ˆ: ê³µí†µìˆ˜í•™1 ëŒ€ì‹  ê³µí†µìˆ˜í•™2)ìœ¼ë¡œ ë¶„ë¥˜í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤!")

        # ì¶œì œë²”ìœ„ ì œí•œ ê°€ì´ë“œë¼ì¸ (ìµœìš°ì„ )
        if context.exam_scope and len(context.exam_scope) > 0:
            scope_list = ", ".join(context.exam_scope)
            guidelines.append(f"âš ï¸ ì¶œì œë²”ìœ„ ì œí•œ: ì´ ì‹œí—˜ì§€ëŠ” ë‹¤ìŒ ë‹¨ì›ìœ¼ë¡œ ì œí•œë©ë‹ˆë‹¤: {scope_list}")
            guidelines.append(f"ê° ë¬¸ì œë¥¼ ì¶œì œë²”ìœ„({scope_list}) ë‚´ ë‹¨ì›ìœ¼ë¡œë§Œ ë¶„ë¥˜í•˜ì„¸ìš”.")
            guidelines.append("ë²”ìœ„ ì™¸ ë‹¨ì›ìœ¼ë¡œ ë¶„ë¥˜ëœ ê²½ìš°, ê°€ì¥ ìœ ì‚¬í•œ ë²”ìœ„ ë‚´ ë‹¨ì›ì„ ì¬ì„ íƒí•˜ì„¸ìš”.")
            guidelines.append("ë²”ìœ„ ë‚´ ì í•©í•œ ë‹¨ì›ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ë§Œ confidenceë¥¼ ë‚®ê²Œ(0.3 ì´í•˜) ì„¤ì •í•˜ì„¸ìš”.")

        # ì‹œí—˜ì§€ ìœ í˜•ë³„ ê°€ì´ë“œë¼ì¸
        if context.exam_paper_type == "blank":
            guidelines.append("ì´ ì‹œí—˜ì§€ëŠ” ë¹ˆ ì‹œí—˜ì§€ì…ë‹ˆë‹¤. ë¬¸ì œ ì¶”ì¶œì— ì§‘ì¤‘í•˜ì„¸ìš”.")
            guidelines.append("ë‹µì•ˆ ë¶„ì„ì€ ê±´ë„ˆë›°ê³ , ë¬¸ì œ ìœ í˜•ê³¼ ë‚œì´ë„ë§Œ ë¶„ì„í•˜ì„¸ìš”.")

        elif context.exam_paper_type == "answered":
            guidelines.append("í•™ìƒ ë‹µì•ˆì´ ì‘ì„±ëœ ì‹œí—˜ì§€ì…ë‹ˆë‹¤.")
            guidelines.append("ê° ë¬¸í•­ì˜ ë‹µì•ˆì„ ë¶„ì„í•˜ê³  ì˜¤ë¥˜ íŒ¨í„´ì„ ì‹ë³„í•˜ì„¸ìš”.")
            guidelines.append("ì±„ì  í‘œì‹œ(O, X)ê°€ ìˆë‹¤ë©´ ì°¸ê³ í•˜ë˜, ì§ì ‘ ì •ì˜¤ íŒë‹¨ë„ ìˆ˜í–‰í•˜ì„¸ìš”.")

        elif context.exam_paper_type == "mixed":
            guidelines.append("ì¼ë¶€ ë¬¸í•­ë§Œ ë‹µì•ˆì´ ì‘ì„±ëœ ì‹œí—˜ì§€ì…ë‹ˆë‹¤.")
            guidelines.append("ë‹µì•ˆì´ ìˆëŠ” ë¬¸í•­ì€ ë¶„ì„í•˜ê³ , ë¹ˆ ë¬¸í•­ì€ ë¬¸ì œë§Œ ì¶”ì¶œí•˜ì„¸ìš”.")

        # í•™ë…„ë³„ ê°€ì´ë“œë¼ì¸ (ê³¼ëª©ë³„ ë¶„ê¸°)
        if context.grade_level:
            subject = context.subject or "ìˆ˜í•™"
            grade_specific = get_grade_guidelines(subject, context.grade_level)
            guidelines.extend(grade_specific)

        # DBì—ì„œ ë¶„ì„ ê°€ì´ë“œ í…œí”Œë¦¿ ì¡°íšŒ
        result = await self.db.table("prompt_templates").select("*").eq(
            "template_type", "analysis_guide"
        ).eq(
            "is_active", True
        ).order(
            "priority", desc=True
        ).execute()

        templates = result.data or []

        for template in templates:
            # ì¡°ê±´ í™•ì¸
            if self._check_conditions(template.get("conditions"), context):
                guidelines.append(template["content"])
                # ì‚¬ìš© íšŸìˆ˜ ì¦ê°€
                await self.db.table("prompt_templates").eq("id", template["id"]).update({
                    "usage_count": template.get("usage_count", 0) + 1
                }).execute()

        return guidelines

    def _get_grade_specific_guidelines(self, grade_level: str) -> list[str]:
        """í•™ë…„ë³„ ë¶„ì„ ê°€ì´ë“œë¼ì¸"""
        grade_guidelines = {
            "ì¤‘1": [
                "ì •ìˆ˜ì™€ ìœ ë¦¬ìˆ˜ ê³„ì‚° ì˜¤ë¥˜ì— ì£¼ì˜í•˜ì„¸ìš”.",
                "ë¬¸ìì™€ ì‹ì—ì„œ ë™ë¥˜í•­ ì²˜ë¦¬ í™•ì¸í•˜ì„¸ìš”.",
            ],
            "ì¤‘2": [
                "ì—°ë¦½ë°©ì •ì‹ í’€ì´ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ í™•ì¸í•˜ì„¸ìš”.",
                "ì¼ì°¨í•¨ìˆ˜ ê·¸ë˜í”„ í•´ì„ ëŠ¥ë ¥ì„ í‰ê°€í•˜ì„¸ìš”.",
            ],
            "ì¤‘3": [
                "ì´ì°¨ë°©ì •ì‹ì˜ ê·¼ì˜ ê³µì‹ ì ìš©ì„ í™•ì¸í•˜ì„¸ìš”.",
                "ì¸ìˆ˜ë¶„í•´ ê³¼ì •ì˜ ì •í™•ì„±ì„ ê²€í† í•˜ì„¸ìš”.",
            ],
            "ê³ 1": [
                "ì§‘í•©ê³¼ ëª…ì œì˜ ë…¼ë¦¬ì  ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                "ë‹¤í•­ì‹ ì—°ì‚°ì˜ ì •í™•ì„±ì„ ê²€í† í•˜ì„¸ìš”.",
            ],
        }
        return grade_guidelines.get(grade_level, [])

    async def _get_error_patterns_prompt(self, context: ExamContext) -> tuple[str, list[str]]:
        """ì˜¤ë¥˜ íŒ¨í„´ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        matched_types = []

        # ê°ì§€ëœ ë¬¸ì œ ìœ í˜•ì— í•´ë‹¹í•˜ëŠ” ì˜¤ë¥˜ íŒ¨í„´ ì¡°íšŒ
        if context.detected_types:
            result = await self.db.table("error_patterns").select(
                "*, problem_types(*)"
            ).in_(
                "problem_type_id", context.detected_types
            ).eq(
                "is_active", True
            ).order(
                "occurrence_count", desc=True
            ).execute()
            patterns = result.data or []
        else:
            # ì „ì²´ í™œì„± íŒ¨í„´ ì¤‘ ë¹ˆë„ ë†’ì€ ê²ƒ
            result = await self.db.table("error_patterns").select(
                "*, problem_types(*)"
            ).eq(
                "is_active", True
            ).order(
                "occurrence_count", desc=True
            ).limit(20).execute()
            patterns = result.data or []

        if not patterns:
            return None, []

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_parts = ["## ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ íŒ¨í„´\në¶„ì„ ì‹œ ë‹¤ìŒ ì˜¤ë¥˜ íŒ¨í„´ë“¤ì„ ì£¼ì˜ ê¹Šê²Œ í™•ì¸í•˜ì„¸ìš”:\n"]

        for pattern in patterns:
            matched_types.append(pattern.get("problem_type_id"))

            prompt_parts.append(f"\n### {pattern.get('name', '')}")
            prompt_parts.append(f"- ìœ í˜•: {pattern.get('error_type', '')}")
            prompt_parts.append(f"- ë¹ˆë„: {pattern.get('frequency', '')}")

            wrong_examples = pattern.get("wrong_examples")
            if wrong_examples:
                prompt_parts.append("- ì˜¤ë‹µ ì˜ˆì‹œ:")
                for ex in wrong_examples[:2]:  # ìµœëŒ€ 2ê°œ
                    prompt_parts.append(f"  - ë¬¸ì œ: {ex.get('problem', '')}")
                    prompt_parts.append(f"    ì˜¤ë‹µ: {ex.get('wrong_answer', '')}")

            prompt_parts.append(f"- ê¶Œì¥ í”¼ë“œë°±: {pattern.get('feedback_message', '')}")

        return "\n".join(prompt_parts), list(set(t for t in matched_types if t))

    async def _get_examples_prompt(self, context: ExamContext, max_per_pattern: int = 2) -> str:
        """ê²€ì¦ëœ ì˜ˆì‹œ + ìŠ¹ì¸ëœ ë ˆí¼ëŸ°ìŠ¤ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt_parts = []

        # 1. ê¸°ì¡´: ê²€ì¦ëœ PatternExample ì¡°íšŒ
        result = await self.db.table("pattern_examples").select(
            "*, error_patterns(*)"
        ).eq(
            "is_verified", True
        ).order(
            "created_at", desc=True
        ).limit(max_per_pattern * 5).execute()

        examples = result.data or []

        if examples:
            prompt_parts.append("## ë¶„ì„ ì˜ˆì‹œ\në‹¤ìŒì€ ê²€ì¦ëœ ë¶„ì„ ì˜ˆì‹œì…ë‹ˆë‹¤:\n")
            for ex in examples:
                error_pattern = ex.get("error_patterns")
                pattern_name = error_pattern.get("name") if error_pattern else "ì¼ë°˜"
                prompt_parts.append(f"\n### ì˜ˆì‹œ: {pattern_name}")
                prompt_parts.append(f"- ë¬¸ì œ: {ex.get('problem_text', '')}")
                prompt_parts.append(f"- í•™ìƒ ë‹µì•ˆ: {ex.get('student_answer', '')}")
                prompt_parts.append(f"- ì •ë‹µ: {ex.get('correct_answer', '')}")
                if ex.get("ai_analysis"):
                    prompt_parts.append(f"- ë¶„ì„ ê²°ê³¼: {ex.get('ai_analysis')}")

        # 2. ì‹ ê·œ: ìŠ¹ì¸ëœ QuestionReference ì¡°íšŒ (í•™ë…„ë³„ í•„í„°ë§!)
        references = await self._get_approved_references(
            grade_level=context.grade_level,
            limit=5
        )

        if references:
            prompt_parts.append("\n## ì°¸ê³  ë¬¸ì œ ë¶„ì„ (í•™ë…„ë³„ ë ˆí¼ëŸ°ìŠ¤)\nì´ì „ ë¶„ì„ì—ì„œ ê²€í† ëœ ë¬¸ì œë“¤ì…ë‹ˆë‹¤:\n")
            for ref in references:
                prompt_parts.append(f"\n### ì°¸ê³  (í•™ë…„: {ref.get('grade_level', '')})")
                if ref.get("topic"):
                    prompt_parts.append(f"- ë‹¨ì›: {ref.get('topic')}")
                prompt_parts.append(f"- ë‚œì´ë„: {ref.get('difficulty', '')}")
                if ref.get("ai_comment"):
                    prompt_parts.append(f"- ë¶„ì„: {ref.get('ai_comment')}")
                confidence = ref.get("confidence", 1.0)
                if confidence < 0.7:
                    prompt_parts.append(f"- ì£¼ì˜: ì´ ìœ í˜•ì˜ ë¬¸ì œëŠ” ë¶„ì„ ì‹œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤ (ê¸°ì¡´ ì‹ ë¢°ë„: {confidence:.2f})")

        if not prompt_parts:
            return None

        return "\n".join(prompt_parts)

    async def _get_approved_references(self, grade_level: str | None, limit: int = 5) -> list[dict]:
        """ìŠ¹ì¸ëœ ë ˆí¼ëŸ°ìŠ¤ ì¡°íšŒ (í•™ë…„ë³„ í•„í„°ë§)

        Args:
            grade_level: í•™ë…„ (ì˜ˆ: "ì¤‘1", "ê³ 1")
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜

        Returns:
            ìŠ¹ì¸ëœ QuestionReference ëª©ë¡
        """
        query = self.db.table("question_references").select("*").eq(
            "review_status", "approved"
        )

        # í•™ë…„ë³„ í•„í„°ë§ (í•µì‹¬!)
        if grade_level and grade_level not in ("ì „ì²´", "unknown", None):
            query = query.eq("grade_level", grade_level)

        query = query.order("created_at", desc=True).limit(limit)

        result = await query.execute()
        return result.data or []

    def _get_paper_type_instructions(self, context: ExamContext) -> str:
        """ì‹œí—˜ì§€ ìœ í˜•ë³„ ì¶”ê°€ ì§€ì‹œì‚¬í•­"""
        instructions = {
            "blank": """
## ë¹ˆ ì‹œí—˜ì§€ ë¶„ì„ ì§€ì¹¨
- ë¬¸ì œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì„¸ìš”
- ë‹µì•ˆ í•„ë“œëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ë‘ì„¸ìš”
- ë¬¸ì œ ìœ í˜•ê³¼ ë‚œì´ë„ ë¶„ë¥˜ì— ì§‘ì¤‘í•˜ì„¸ìš”
""",
            "answered": """
## í•™ìƒ ë‹µì•ˆ ë¶„ì„ ì§€ì¹¨
- ê° ë¬¸í•­ì˜ í•™ìƒ ë‹µì•ˆì„ ì •í™•íˆ ì¸ì‹í•˜ì„¸ìš”
- í’€ì´ ê³¼ì •ì´ ìˆë‹¤ë©´ í•¨ê»˜ ë¶„ì„í•˜ì„¸ìš”
- ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ë©´ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ìœ í˜•ì„ ëª…ì‹œí•˜ì„¸ìš”
- ì±„ì  í‘œì‹œ(O, X, ì ìˆ˜)ê°€ ìˆë‹¤ë©´ ê¸°ë¡í•˜ì„¸ìš”
""",
            "mixed": """
## í˜¼í•© ì‹œí—˜ì§€ ë¶„ì„ ì§€ì¹¨
- ë‹µì•ˆì´ ìˆëŠ” ë¬¸í•­ê³¼ ì—†ëŠ” ë¬¸í•­ì„ êµ¬ë¶„í•˜ì„¸ìš”
- ë‹µì•ˆ ìˆëŠ” ë¬¸í•­: ì˜¤ë¥˜ ë¶„ì„ ìˆ˜í–‰
- ë‹µì•ˆ ì—†ëŠ” ë¬¸í•­: ë¬¸ì œ ì¶”ì¶œë§Œ ìˆ˜í–‰
""",
        }
        return instructions.get(context.exam_paper_type, "")

    def _check_conditions(self, conditions: dict | None, context: ExamContext) -> bool:
        """í…œí”Œë¦¿ ì ìš© ì¡°ê±´ í™•ì¸"""
        if not conditions:
            return True

        # í•™ë…„ ì¡°ê±´
        if "grade_levels" in conditions and conditions["grade_levels"]:
            if context.grade_level not in conditions["grade_levels"]:
                return False

        # ë¬¸í•­ ìˆ˜ ì¡°ê±´
        if "min_questions" in conditions and context.question_count:
            if context.question_count < conditions["min_questions"]:
                return False

        if "max_questions" in conditions and context.question_count:
            if context.question_count > conditions["max_questions"]:
                return False

        # ì‹œí—˜ì§€ ìœ í˜• ì¡°ê±´
        if "exam_paper_type" in conditions and conditions["exam_paper_type"]:
            if context.exam_paper_type != conditions["exam_paper_type"]:
                return False

        return True

    def _combine_prompts(
        self,
        base_prompt: str,
        guidelines: list[str],
        error_patterns: str | None,
        examples: str | None,
        paper_type_instructions: str,
        exam_paper_type: str = "blank",
        subject: str = "ìˆ˜í•™",
        grade_level: str | None = None,
        category: str | None = None,
    ) -> str:
        """ëª¨ë“  í”„ë¡¬í”„íŠ¸ ìš”ì†Œ ì¡°í•©"""
        parts = [base_prompt]

        if guidelines:
            parts.append("\n## ë¶„ì„ ê°€ì´ë“œë¼ì¸")
            for g in guidelines:
                parts.append(f"- {g}")

        if paper_type_instructions:
            parts.append(paper_type_instructions)

        if error_patterns:
            parts.append(error_patterns)

        if examples:
            parts.append(examples)

        # JSON ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì¶”ê°€ (í•„ìˆ˜!)
        json_schema = self._get_json_schema(exam_paper_type, subject, grade_level, category)
        parts.append(json_schema)

        return "\n".join(parts)

    def _get_json_schema(self, exam_paper_type: str, subject: str = "ìˆ˜í•™", grade_level: str | None = None, category: str | None = None) -> str:
        """ë¶„ì„ ê²°ê³¼ JSON ìŠ¤í‚¤ë§ˆ ë°˜í™˜ (ê³¼ëª©ë³„ ë¶„ê¸°)"""
        if subject == "ì˜ì–´":
            return self._get_english_json_schema(exam_paper_type)
        return self._get_math_json_schema(exam_paper_type, grade_level, category)

    # ê³¼ëª©ë³„ ì˜ˆì‹œ í† í”½ ë§¤í•‘
    CATEGORY_TOPIC_EXAMPLES = {
        "ê³µí†µìˆ˜í•™1": "ê³µí†µìˆ˜í•™1 > ë‹¤í•­ì‹ > ë‹¤í•­ì‹ì˜ ì—°ì‚°",
        "ê³µí†µìˆ˜í•™2": "ê³µí†µìˆ˜í•™2 > ë„í˜•ì˜ ë°©ì •ì‹ > í‰ë©´ì¢Œí‘œ",
        "ëŒ€ìˆ˜": "ëŒ€ìˆ˜ > ì§€ìˆ˜í•¨ìˆ˜ì™€ ë¡œê·¸í•¨ìˆ˜ > ì§€ìˆ˜í•¨ìˆ˜",
        "ë¯¸ì ë¶„â… ": "ë¯¸ì ë¶„â…  > ë¯¸ë¶„ > ë¯¸ë¶„ê³„ìˆ˜ì™€ ë„í•¨ìˆ˜",
        "ë¯¸ì ë¶„I": "ë¯¸ì ë¶„I > ë¯¸ë¶„ > ë¯¸ë¶„ê³„ìˆ˜ì™€ ë„í•¨ìˆ˜",
        "ë¯¸ì ë¶„â…¡": "ë¯¸ì ë¶„â…¡ > ì—¬ëŸ¬ ê°€ì§€ ë¯¸ë¶„ë²• > ì—¬ëŸ¬ ê°€ì§€ í•¨ìˆ˜ì˜ ë¯¸ë¶„",
        "ë¯¸ì ë¶„II": "ë¯¸ì ë¶„II > ì—¬ëŸ¬ ê°€ì§€ ë¯¸ë¶„ë²• > ì—¬ëŸ¬ ê°€ì§€ í•¨ìˆ˜ì˜ ë¯¸ë¶„",
        "í™•ë¥ ê³¼ í†µê³„": "í™•ë¥ ê³¼ í†µê³„ > í™•ë¥  > ì¡°ê±´ë¶€ í™•ë¥ ",
        "ê¸°í•˜": "ê¸°í•˜ > ì´ì°¨ê³¡ì„  > í¬ë¬¼ì„ ",
    }

    def _get_math_json_schema(self, exam_paper_type: str, grade_level: str | None = None, category: str | None = None) -> str:
        """ìˆ˜í•™ ê³¼ëª© JSON ìŠ¤í‚¤ë§ˆ (í•™ë…„ë³„ ì„ íƒì  ì½˜í…ì¸  í¬í•¨)"""
        # ì˜ˆì‹œ í† í”½ ë™ì  ê²°ì •
        example_topic = self.CATEGORY_TOPIC_EXAMPLES.get(category, "ê³µí†µìˆ˜í•™1 > ë‹¤í•­ì‹ > ë‹¤í•­ì‹ì˜ ì—°ì‚°") if category else "ê³µí†µìˆ˜í•™1 > ë‹¤í•­ì‹ > ë‹¤í•­ì‹ì˜ ì—°ì‚°"

        base_schema = f"""
## í•„ìˆ˜ ì‘ë‹µ í˜•ì‹ (JSON)

ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¶œë ¥í•˜ì„¸ìš”:

{{
    "exam_info": {{
        "total_questions": 21,
        "total_points": 100,
        "format_distribution": {{
            "objective": 16,
            "short_answer": 0,
            "essay": 5
        }}
    }},
    "summary": {{
        "difficulty_distribution": {{"concept": 0, "pattern": 0, "reasoning": 0, "creative": 0}},
        "type_distribution": {{
            "calculation": 0, "geometry": 0, "application": 0,
            "proof": 0, "graph": 0, "statistics": 0
        }},
        "average_difficulty": "pattern",
        "dominant_type": "calculation"
    }},
    "questions": [
        {{
            "question_number": 1,
            "question_format": "objective",
            "difficulty": "concept",
            "question_type": "calculation",
            "points": 3,
            "topic": "{example_topic}",
            "ai_comment": "í•µì‹¬ ê°œë…. ì£¼ì˜ì‚¬í•­.",
            "confidence": 0.95,
            "difficulty_reason": "ê¸°ë³¸ ê°œë… í™•ì¸"
"""

        # í•™ìƒ ë‹µì•ˆì´ ìˆëŠ” ê²½ìš° ì¶”ê°€ í•„ë“œ
        if exam_paper_type in ["answered", "mixed", "student"]:
            base_schema += """,
            "is_correct": true,
            "student_answer": "3",
            "earned_points": 3,
            "error_type": null"""

        # JSON êµ¬ì¡° ë‹«ê¸°
        base_schema += """
        }
    ]
}

## í† í”½ ë¶„ë¥˜í‘œ (ì •í™•íˆ ì‚¬ìš©)

"""
        # ê³¼ëª© ë§¤ì¹­ ê·œì¹™ (ê³ ë“±í•™êµì¼ ë•Œë§Œ í¬í•¨)
        if not grade_level or grade_level.startswith("ê³ "):
            base_schema += SUBJECT_MATCHING_RULES + "\n\n"

        # í•™êµê¸‰ ë¶„ë¦¬ ê·œì¹™
        base_schema += SCHOOL_LEVEL_RULES + "\n\n"

        # í•™ë…„ë³„ í† í”½ ë¶„ë¥˜í‘œ (í•µì‹¬ í† í° ì ˆê° í¬ì¸íŠ¸!)
        base_schema += get_topics_for_grade(grade_level) + "\n\n"

        # ê·œì¹™ (í•­ìƒ í¬í•¨ - ì»´íŒ©íŠ¸)
        base_schema += """## ê·œì¹™ (ì—„ê²© ì¤€ìˆ˜)

1. ëª¨ë“  í…ìŠ¤íŠ¸(topic, ai_comment)ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
2. question_format: objective(ê°ê´€ì‹), short_answer(ë‹¨ë‹µí˜•), essay(ì„œìˆ í˜•/ì„œë‹µí˜•) ì¤‘ í•˜ë‚˜
3. difficulty: concept(ê°œë…), pattern(ìœ í˜•), reasoning(ì‚¬ê³ ë ¥), creative(ì°½ì˜) ì¤‘ í•˜ë‚˜ (4ë‹¨ê³„ ì‹œìŠ¤í…œ)
4. question_type: calculation(ê³„ì‚°), geometry(ë„í˜•), application(ì‘ìš©), proof(ì¦ëª…), graph(ê·¸ë˜í”„), statistics(í†µê³„) ì¤‘ í•˜ë‚˜
5. points: ìˆ«ì (ì†Œìˆ˜ì  í—ˆìš©)
6. **topic í˜•ì‹ (í•„ìˆ˜)**: "ê³¼ëª©ëª… > ëŒ€ë‹¨ì› > ì†Œë‹¨ì›"
   - âœ… ì˜¬ë°”ë¥¸ ì˜ˆ:
     - "ì¤‘3 ìˆ˜í•™ > ë‹¤í•­ì‹ì˜ ê³±ì…ˆê³¼ ì¸ìˆ˜ë¶„í•´ > ì¸ìˆ˜ë¶„í•´"
     - "ê³µí†µìˆ˜í•™1 > ë‹¤í•­ì‹ > ë‹¤í•­ì‹ì˜ ì—°ì‚°"
     - "ê³ 1 ìˆ˜í•™ > ë°©ì •ì‹ê³¼ ë¶€ë“±ì‹ > ì´ì°¨ë°©ì •ì‹" (ë³µí•© ë¬¸ì œë„ ì£¼ìš” ê°œë… í•˜ë‚˜ë§Œ)
   - âŒ ì˜ëª»ëœ ì˜ˆ:
     - "[ì¤‘3 ìˆ˜í•™] ì¸ìˆ˜ë¶„í•´" (> êµ¬ë¶„ì ì—†ìŒ)
     - "[ìˆ˜ì™€ ì—°ì‚°] ì œê³±ê·¼ê³¼ ì‹¤ìˆ˜" (ê³¼ëª©ëª… ì—†ìŒ)
     - "ì¤‘3 ìˆ˜í•™ > [ë‹¤í•­ì‹ì˜ ê³±ì…ˆê³¼ ì¸ìˆ˜ë¶„í•´] ì¸ìˆ˜ë¶„í•´" ([] ì‚¬ìš©)
     - "ë¡œê·¸ë°©ì •ì‹ê³¼ ì´ì°¨ë°©ì •ì‹ì˜ íŒë³„ì‹" (âŒ ë³µí•© í† í”½ ê¸ˆì§€)
     - "ì§€ìˆ˜í•¨ìˆ˜ì™€ ë¡œê·¸í•¨ìˆ˜ì˜ í™œìš©" (âŒ ì—¬ëŸ¬ ë‹¨ì› í•©ì¹˜ê¸° ê¸ˆì§€)
   - **ë°˜ë“œì‹œ " > " (ê³µë°±-êº½ì‡ -ê³µë°±)ë¡œ êµ¬ë¶„**
   - **[] ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€**
   - **âš ï¸ ë³µí•© í† í”½ ê¸ˆì§€**: ì—¬ëŸ¬ ê°œë…ì´ ìœµí•©ëœ ë¬¸ì œë„ **í•µì‹¬ ê°œë… í•˜ë‚˜ë§Œ** ì„ íƒ
7. ai_comment: ì •í™•íˆ 2ë¬¸ì¥, ì´ 50ì ì´ë‚´
8. confidence: í•´ë‹¹ ë¬¸í•­ ë¶„ì„ì˜ í™•ì‹ ë„ (0.0 ~ 1.0)
9. question_number: ìˆ«ì ë˜ëŠ” "ì„œìˆ í˜• 1", "ì„œë‹µí˜• 2" í˜•ì‹
10. difficulty_reason: ë‚œì´ë„ íŒë‹¨ ê·¼ê±° (15ì ì´ë‚´)
    - concept: "ê¸°ë³¸ ê°œë… í™•ì¸", "ê³µì‹ ì§ì ‘ ëŒ€ì…", "1ë‹¨ê³„ í•´ê²°" ë“±
    - pattern: "ì¼ë°˜ ìœ í˜•", "2-3ë‹¨ê³„ í’€ì´", "êµê³¼ì„œ ì—°ìŠµë¬¸ì œ" ë“±
    - reasoning: "2ê°œ ëŒ€ë‹¨ì› ë³µí•©", "5-6ë‹¨ê³„ í’€ì´", "ë…¼ë¦¬ì  ì¶”ë¡ " ë“±
    - creative: "3ê°œ ëŒ€ë‹¨ì› ë³µí•©", "ì°½ì˜ì  í†µì°°", "7ë‹¨ê³„ ì´ìƒ í’€ì´" ë“±

"""
        # 4ë‹¨ê³„ ë‚œì´ë„ ì‹œìŠ¤í…œ (configì—ì„œ ì°¸ì¡°)
        base_schema += DIFFICULTY_SYSTEM_4LEVEL + "\n\n"

        # ì„œìˆ í˜• ë¶„ì„ ê°€ì´ë“œ (configì—ì„œ ì°¸ì¡°)
        base_schema += ESSAY_ANALYSIS_FULL_GUIDE + "\n\n"

        # í•™ë…„ë³„ í”í•œ ì‹¤ìˆ˜ ìœ í˜• (ì„ íƒì  í¬í•¨)
        mistakes = get_mistakes_for_grade(grade_level)
        if mistakes:
            base_schema += "ğŸ” **[ì°¸ê³ ] ë‹¨ì›ë³„ í”í•œ ì‹¤ìˆ˜ ìœ í˜• (ai_comment ì‘ì„± ì‹œ í™œìš©)**\n\n"
            base_schema += mistakes + "\n\n"

        # ê³ ë“±í•™êµ: ì¤‘â†’ê³  êµìœ¡ê³¼ì • ì—°ê³„ / ì¤‘í•™êµ: í•™ìŠµ í¬ì¸íŠ¸
        prerequisite = get_prerequisite_if_high_school(grade_level)
        if prerequisite:
            base_schema += prerequisite + "\n\n"

        study_points = get_middle_study_points(grade_level)
        if study_points:
            base_schema += study_points + "\n\n"

        # ì†Œë¬¸ì œ ì²˜ë¦¬ ê·œì¹™ (í•­ìƒ í¬í•¨)
        base_schema += """âš ï¸ ì¤‘ìš” - ì†Œë¬¸ì œ ì²˜ë¦¬:
- (1), (2), (3) ë˜ëŠ” (ê°€), (ë‚˜), (ë‹¤)ê°€ ìˆìœ¼ë©´ í•˜ë‚˜ì˜ ë¬¸ì œë¡œ ì·¨ê¸‰
- ë°°ì ì€ í•©ì‚°
- ë‚œì´ë„ëŠ” ê°€ì¥ ì–´ë ¤ìš´ ì†Œë¬¸ì œ ê¸°ì¤€

"""
        # ë°°ì  ê²€ì¦ + ê³¼ëª© ë¶„ë¥˜ ì›ì¹™ (configì—ì„œ ì°¸ì¡°)
        base_schema += POINTS_VALIDATION_RULES + "\n\n"
        base_schema += EXAM_SUBJECT_CLASSIFICATION + "\n"

        if exam_paper_type in ["answered", "mixed", "student"]:
            base_schema += """
## ì˜¤ë¥˜ ìœ í˜• (error_type)

- calculation_error: ê³„ì‚° ì‹¤ìˆ˜ (ë¶€í˜¸, ì‚¬ì¹™ì—°ì‚° ë“±)
- concept_error: ê°œë… ì˜¤í•´ (ê³µì‹, ì •ì˜ ë“±)
- careless_mistake: ë‹¨ìˆœ ì‹¤ìˆ˜ (ë¬¸ì œ ì˜ëª» ì½ìŒ, ë‹µì•ˆ ì˜ëª» ê¸°ì¬)
- process_error: í’€ì´ ê³¼ì • ì˜¤ë¥˜ (ë…¼ë¦¬ì  ë¹„ì•½)
- incomplete: ë¯¸ì™„ì„± (ì‹œê°„ ë¶€ì¡±, í¬ê¸°)

âš ï¸ ì¤‘ìš” - ì •ì˜¤ë‹µ ì¸ì‹:
- O, â—‹, âœ“, ë™ê·¸ë¼ë¯¸ = ì •ë‹µ (is_correct: true)
- X, âœ—, ë¹—ê¸ˆ, ë¹¨ê°„ ì¤„ = ì˜¤ë‹µ (is_correct: false)
- ë¶€ë¶„ ì ìˆ˜ê°€ ìˆìœ¼ë©´ earned_pointsì— ë°˜ì˜
- ì±„ì  í‘œì‹œê°€ ì—†ìœ¼ë©´ is_correct: null
"""

        return base_schema

    def _get_english_json_schema(self, exam_paper_type: str) -> str:
        """ì˜ì–´ ê³¼ëª© JSON ìŠ¤í‚¤ë§ˆ"""
        base_schema = """
## í•„ìˆ˜ ì‘ë‹µ í˜•ì‹ (JSON)

ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¶œë ¥í•˜ì„¸ìš”:

{
    "exam_info": {
        "total_questions": 25,
        "total_points": 100,
        "format_distribution": {
            "objective": 20,
            "short_answer": 3,
            "essay": 2
        }
    },
    "summary": {
        "difficulty_distribution": {"concept": 0, "pattern": 0, "reasoning": 0, "creative": 0},
        "type_distribution": {
            "vocabulary": 0, "grammar": 0, "reading_main_idea": 0,
            "reading_detail": 0, "reading_inference": 0,
            "listening": 0, "writing": 0, "sentence_completion": 0,
            "conversation": 0
        },
        "average_difficulty": "pattern",
        "dominant_type": "grammar"
    },
    "questions": [
        {
            "question_number": 1,
            "question_format": "objective",
            "difficulty": "concept",
            "question_type": "grammar",
            "points": 3,
            "topic": "ì¤‘2 ì˜ì–´ > ë¬¸ë²• > toë¶€ì •ì‚¬",
            "ai_comment": "toë¶€ì •ì‚¬ ìš©ë²• êµ¬ë¶„. ê¸°ì´ˆ ë¬¸ë²•.",
            "confidence": 0.95,
            "difficulty_reason": "ê¸°ë³¸ ë¬¸ë²• ì ìš©"
"""

        # í•™ìƒ ë‹µì•ˆì´ ìˆëŠ” ê²½ìš° ì¶”ê°€ í•„ë“œ
        if exam_paper_type in ["answered", "mixed", "student"]:
            base_schema += """,
            "is_correct": true,
            "student_answer": "2",
            "earned_points": 3,
            "error_type": null"""

        # JSON êµ¬ì¡° ë‹«ê¸°
        base_schema += """
        }
    ]
}

## í† í”½ ë¶„ë¥˜í‘œ (ì˜ì–´)

âš ï¸ ì‹œí—˜ì§€ ìƒë‹¨ì˜ í•™ë…„ ì •ë³´ë¥¼ í™•ì¸í•˜ê³  í•´ë‹¹ í•™êµê¸‰ì˜ ë¶„ë¥˜í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!

### ã€ì¤‘í•™êµã€‘

[ì¤‘1 ì˜ì–´]
- ë¬¸ë²•: beë™ì‚¬, ì¼ë°˜ë™ì‚¬, í˜„ì¬ì‹œì œ, ê³¼ê±°ì‹œì œ, ë¯¸ë˜ì‹œì œ, ëª…ë ¹ë¬¸, ì˜ë¬¸ë¬¸
- ì–´íœ˜: ê¸°ì´ˆ ì–´íœ˜ (ê°€ì¡±, í•™êµ, ìŒì‹, ë‚ ì”¨, ì·¨ë¯¸ ë“±)
- ë…í•´: ì§§ì€ ëŒ€í™”ë¬¸, ê°„ë‹¨í•œ ì•ˆë‚´ë¬¸, ì¼ê¸°/í¸ì§€
- ë“£ê¸°: ê¸°ì´ˆ ëŒ€í™” ë“£ê¸°, ê°„ë‹¨í•œ ì •ë³´ íŒŒì•…

[ì¤‘2 ì˜ì–´]
- ë¬¸ë²•: toë¶€ì •ì‚¬, ë™ëª…ì‚¬, ì¡°ë™ì‚¬(can/may/must), ë¹„êµê¸‰/ìµœìƒê¸‰, ì ‘ì†ì‚¬
- ì–´íœ˜: ì¤‘ê¸‰ ì–´íœ˜ (ê°ì •, ì§ì—…, ì—¬í–‰, ê±´ê°• ë“±)
- ë…í•´: ì¤‘ê°„ ê¸¸ì´ ì§€ë¬¸, ëŒ€ì˜íŒŒì•…, ì„¸ë¶€ì •ë³´ ì°¾ê¸°
- ë“£ê¸°: ëŒ€í™” ì„¸ë¶€ì •ë³´, ê·¸ë¦¼/ë„í‘œ ì—°ê²°

[ì¤‘3 ì˜ì–´]
- ë¬¸ë²•: ê´€ê³„ëŒ€ëª…ì‚¬(who/which/that), í˜„ì¬ì™„ë£Œ, ìˆ˜ë™íƒœ, ë¶„ì‚¬, ê°„ì ‘ì˜ë¬¸ë¬¸
- ì–´íœ˜: ê³ ê¸‰ ì–´íœ˜ (í™˜ê²½, ê³¼í•™, ë¬¸í™”, ì‚¬íšŒ ë“±)
- ë…í•´: ê¸´ ì§€ë¬¸, ì¶”ë¡ , ìš”ì§€/ì£¼ì œ íŒŒì•…
- ë“£ê¸°: ë‹´í™” ë“£ê¸°, í™”ì ì˜ë„ íŒŒì•…

### ã€ê³ ë“±í•™êµã€‘

[ê³ 1 ì˜ì–´]
- ë¬¸ë²•: ê°€ì •ë²• ê³¼ê±°/ê³¼ê±°ì™„ë£Œ, ë¶„ì‚¬êµ¬ë¬¸, ê°•ì¡°/ë„ì¹˜ êµ¬ë¬¸, ê´€ê³„ë¶€ì‚¬
- ì–´íœ˜: ìˆ˜ëŠ¥ ê¸°ë³¸ ì–´íœ˜, ì–´ê·¼/ì ‘ì‚¬
- ë…í•´: ë¹ˆì¹¸ ì¶”ë¡ , ë¬¸ì¥ ì‚½ì…, ê¸€ì˜ ìˆœì„œ
- ë“£ê¸°: ìˆ˜ëŠ¥í˜• ë“£ê¸° (ëª©ì /ì£¼ì œ/ìš”ì§€)

[ê³ 2 ì˜ì–´]
- ë¬¸ë²•: ë³µì¡í•œ êµ¬ë¬¸ ë¶„ì„, ë™ì‚¬ì˜ ë‹¤ì–‘í•œ ìš©ë²•
- ì–´íœ˜: ìˆ˜ëŠ¥ í•„ìˆ˜ ì–´íœ˜, ë™ì˜ì–´/ë°˜ì˜ì–´, ë¬¸ë§¥ìƒ ì–´íœ˜
- ë…í•´: í•¨ì¶• ì˜ë¯¸ ì¶”ë¡ , ì‹¬ê²½/ë¶„ìœ„ê¸° íŒŒì•…, ìš”ì•½ë¬¸ ì™„ì„±
- ë“£ê¸°: ë‹´í™” ì™„ì„±, í™”ì ê´€ê³„ íŒŒì•…

[ê³ 3 ì˜ì–´]
- ë¬¸ë²•: ê³ ë‚œë„ êµ¬ë¬¸, ë¬¸ë²•ì„± íŒë‹¨
- ì–´íœ˜: ê³ ê¸‰ ì–´íœ˜, ë‹¤ì˜ì–´, ì—°ì–´(collocation)
- ë…í•´: ì¥ë¬¸ ë…í•´, ë³µí•© ì¶”ë¡ , ì‹¤ìš©ë¬¸ ë¶„ì„
- ë“£ê¸°: ìˆ˜ëŠ¥ ì‹¤ì „ ë“£ê¸° ì „ ìœ í˜•

## ê·œì¹™ (ì—„ê²© ì¤€ìˆ˜)

1. ëª¨ë“  í…ìŠ¤íŠ¸(topic, ai_comment)ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
2. question_format: objective(ê°ê´€ì‹), short_answer(ë‹¨ë‹µí˜•), essay(ì„œìˆ í˜•/ì„œë‹µí˜•) ì¤‘ í•˜ë‚˜
3. difficulty: concept(ê°œë…), pattern(ìœ í˜•), reasoning(ì‚¬ê³ ë ¥), creative(ì°½ì˜) ì¤‘ í•˜ë‚˜ (4ë‹¨ê³„ ì‹œìŠ¤í…œ)
4. question_type: vocabulary(ì–´íœ˜), grammar(ë¬¸ë²•), reading_main_idea(ëŒ€ì˜íŒŒì•…), reading_detail(ì„¸ë¶€ì •ë³´), reading_inference(ì¶”ë¡ ), listening(ë“£ê¸°), writing(ì˜ì‘), sentence_completion(ë¬¸ì¥ì™„ì„±), conversation(ëŒ€í™”ë¬¸) ì¤‘ í•˜ë‚˜
5. points: ìˆ«ì (ì†Œìˆ˜ì  í—ˆìš©)
6. topic í˜•ì‹: "í•™ë…„ ì˜ì–´ > ëŒ€ì˜ì—­ > ì„¸ë¶€ì˜ì—­" (ë³µí•© í† í”½ ê¸ˆì§€, í•µì‹¬ ì˜ì—­ í•˜ë‚˜ë§Œ ì„ íƒ)
7. ai_comment: ì •í™•íˆ 2ë¬¸ì¥, ì´ 50ì ì´ë‚´
8. confidence: í•´ë‹¹ ë¬¸í•­ ë¶„ì„ì˜ í™•ì‹ ë„ (0.0 ~ 1.0)
9. question_number: ìˆ«ì ë˜ëŠ” "ì„œìˆ í˜• 1" í˜•ì‹
10. difficulty_reason: ë‚œì´ë„ íŒë‹¨ ê·¼ê±° (15ì ì´ë‚´)
    - concept: "ê¸°ì´ˆ ë¬¸ë²•", "ì‰¬ìš´ ì–´íœ˜", "ëª…ì‹œì  ì •ë³´" ë“±
    - pattern: "ì¤‘ê¸‰ ë¬¸ë²•", "ì¼ë°˜ ì–´íœ˜", "2-3ë‹¨ê³„ ì¶”ë¡ " ë“±
    - reasoning: "ë³µí•© êµ¬ë¬¸", "ë‹¤ì¸µ ì¶”ë¡ ", "ì•”ì‹œì  ì •ë³´" ë“±
    - creative: "ë³µí•© êµ¬ë¬¸+ê³ ë‚œë„ ì¶”ë¡ ", "ê¸´ ì§€ë¬¸+ë‹¤ì¸µ ì¶”ë¡ ", "ì°½ì˜ì  í•´ì„" ë“±

ğŸš¨ **4ë‹¨ê³„ ë‚œì´ë„ ì‹œìŠ¤í…œ (ì˜ì–´ ê³¼ëª©)**:

**í•µì‹¬ ì›ì¹™: ì–¸ì–´ ì´í•´ ë° ì¶”ë¡ ì˜ ê¹Šì´ë¡œ íŒë‹¨!**

### 1ï¸âƒ£ concept (ê°œë…) - ê¸°ì´ˆ ê°œë… ì§ì ‘ ì ìš©
- ê¸°ì´ˆ ë¬¸ë²• ê·œì¹™ ê·¸ëŒ€ë¡œ ì ìš©, ì‰¬ìš´ ì–´íœ˜ (ì¤‘1-ì¤‘2 ìˆ˜ì¤€)
- ëª…ì‹œì ìœ¼ë¡œ ì œì‹œëœ ì •ë³´ ì°¾ê¸°
- 1-2ë‹¨ê³„ë¡œ ì¦‰ì‹œ í•´ê²°
- ì˜ˆ: "beë™ì‚¬ ì±„ìš°ê¸°", "ë°‘ì¤„ ì¹œ ë‹¨ì–´ì˜ ëœ»ì€?"

### 2ï¸âƒ£ pattern (ìœ í˜•) - ì¼ë°˜ ìœ í˜• ë¬¸ì œ
- ì¤‘ê¸‰ ë¬¸ë²• (toë¶€ì •ì‚¬, ê´€ê³„ì‚¬ ë“±), ì¼ë°˜ ì–´íœ˜
- êµê³¼ì„œ ìœ í˜•, 2-3ë‹¨ê³„ ì¶”ë¡ 
- ë¬¸ë§¥ì—ì„œ ì •ë³´ ì—°ê²° í•„ìš”
- ì˜ˆ: "ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ ë§", "ê¸€ì˜ ì£¼ì œ"

### 3ï¸âƒ£ reasoning (ì‹¬í™”) - ë³µí•© ì‚¬ê³ ë ¥
- ë³µí•© êµ¬ë¬¸ ë¶„ì„, ë‹¤ì¸µì  ì¶”ë¡ 
- ì•”ì‹œì  ì •ë³´ ì¶”ë¡ , ë¬¸ë‹¨ ê°„ ê´€ê³„ íŒŒì•…
- ì—¬ëŸ¬ ë‹¨ì„œ ì¢…í•© í•„ìš”
- ì˜ˆ: "í•„ìì˜ ìˆ¨ì€ ì˜ë„", "ë‹¤ìŒ ê¸€ì˜ íë¦„ìœ¼ë¡œ ì ì ˆí•œ ê²ƒ"

### 4ï¸âƒ£ creative (ìµœìƒìœ„) - ì°½ì˜ì  í•´ì„ (ê·¹íˆ ë“œë¬¾!)
- ê³ ë‚œë„ êµ¬ë¬¸+ê³ ë‚œë„ ì¶”ë¡  ê²°í•©
- ìˆ˜ëŠ¥ ìµœê³ ë‚œë„ ìˆ˜ì¤€ (33-34ë²ˆ)
- ì°½ì˜ì  í•´ì„ ë° ë¹„íŒì  ì‚¬ê³  í•„ìˆ˜
- **ì›ì¹™**: ì‹œí—˜ë‹¹ ìµœëŒ€ 1ë¬¸ì œ, ì˜ì‹¬ìŠ¤ëŸ¬ìš°ë©´ reasoning!

**â— ì¤‘ìš”:**
- **ê¸´ ì§€ë¬¸ì´ë¼ê³  ë¬´ì¡°ê±´ ë‚œì´ë„ê°€ ë†’ì€ ê²Œ ì•„ë‹˜!**
- **ì„œìˆ í˜•/ì˜ì‘ì´ë¼ê³  ìë™ìœ¼ë¡œ ë†’ì€ ë‚œì´ë„ê°€ ì•„ë‹˜!**
- **ì§€ë¬¸ ê¸¸ì´ê°€ ì•„ë‹Œ ì´í•´/ì¶”ë¡  ê¹Šì´ë¡œ íŒë‹¨!**
- ì• ë§¤í•˜ë©´ í•­ìƒ í•œ ë‹¨ê³„ ë‚®ê²Œ!

âš ï¸ ì¤‘ìš” - ë“£ê¸° ë¬¸í•­ ì²˜ë¦¬:
- ë“£ê¸° ë¬¸í•­ì€ ìŒì„± ì—†ì´ ë¬¸í•­ ìœ í˜•ê³¼ ë‚œì´ë„ë§Œ ë¶„ì„
- question_type: "listening"ìœ¼ë¡œ í‘œê¸°
- topic: "í•™ë…„ ì˜ì–´ > ë“£ê¸° > [ì„¸ë¶€ìœ í˜•]" í˜•ì‹
"""

        if exam_paper_type in ["answered", "mixed", "student"]:
            base_schema += """
## ì˜¤ë¥˜ ìœ í˜• (error_type) - ì˜ì–´

- tense_error: ì‹œì œ ì˜¤ë¥˜ (í˜„ì¬/ê³¼ê±°/ì™„ë£Œ í˜¼ë™)
- word_order_error: ì–´ìˆœ ì˜¤ë¥˜ (ì£¼ì–´-ë™ì‚¬-ëª©ì ì–´ ìˆœì„œ)
- vocabulary_error: ì–´íœ˜ ì˜¤ë¥˜ (ë‹¨ì–´ ì˜ë¯¸ í˜¼ë™, ì² ì ì˜¤ë¥˜)
- comprehension_error: ë…í•´ ì˜¤ë¥˜ (ì§€ë¬¸ ì´í•´ ì‹¤íŒ¨, ì˜ëª»ëœ ì¶”ë¡ )
- listening_error: ì²­ì·¨ ì˜¤ë¥˜ (ë°œìŒ/ì–µì–‘ í˜¼ë™, ì •ë³´ ëˆ„ë½)
- careless_mistake: ë‹¨ìˆœ ì‹¤ìˆ˜ (ì˜¤ë‹µ ë§ˆí‚¹, ë¬¸ì œ ì˜ëª» ì½ìŒ)

âš ï¸ ì¤‘ìš” - ì •ì˜¤ë‹µ ì¸ì‹:
- O, â—‹, âœ“, ë™ê·¸ë¼ë¯¸ = ì •ë‹µ (is_correct: true)
- X, âœ—, ë¹—ê¸ˆ, ë¹¨ê°„ ì¤„ = ì˜¤ë‹µ (is_correct: false)
- ë¶€ë¶„ ì ìˆ˜ê°€ ìˆìœ¼ë©´ earned_pointsì— ë°˜ì˜
- ì±„ì  í‘œì‹œê°€ ì—†ìœ¼ë©´ is_correct: null
"""

        return base_schema


# ì‹œí—˜ì§€ ìœ í˜• ë¶„ë¥˜ ì„œë¹„ìŠ¤
class ExamPaperClassifier:
    """ì‹œí—˜ì§€ ìœ í˜• ìë™ ë¶„ë¥˜"""

    # ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸
    CLASSIFICATION_PROMPT = """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œí—˜ì§€ ìœ í˜•ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

## ë¶„ë¥˜ í•­ëª©
1. paper_type: ì‹œí—˜ì§€ ìœ í˜•
   - "blank": ë¹ˆ ì‹œí—˜ì§€ (ë‹µì•ˆ ì—†ìŒ)
   - "answered": í•™ìƒ ë‹µì•ˆ ì‘ì„±ë¨
   - "mixed": ì¼ë¶€ë§Œ ë‹µì•ˆ ìˆìŒ

2. grading_status: ì±„ì  ìƒíƒœ
   - "not_graded": ì±„ì  ì•ˆë¨
   - "partially_graded": ì¼ë¶€ë§Œ ì±„ì 
   - "fully_graded": ì „ì²´ ì±„ì ë¨

3. ê° ë¬¸í•­ë³„ ì •ë³´:
   - ë‹µì•ˆ ì‘ì„± ì—¬ë¶€
   - ì±„ì  í‘œì‹œ ì—¬ë¶€ (O, X, ì ìˆ˜ ë“±)
   - ì •ë‹µ/ì˜¤ë‹µ ì—¬ë¶€

## íŒë‹¨ ê·¼ê±°
- ì†ê¸€ì”¨ ë‹µì•ˆ ìœ ë¬´
- ì±„ì  í‘œì‹œ (O, X, ë™ê·¸ë¼ë¯¸, ì²´í¬ ë“±)
- ì ìˆ˜ ê¸°ì¬ ì—¬ë¶€
- ë¹¨ê°„íœ/íŒŒë€íœ í‘œì‹œ

## ì‘ë‹µ í˜•ì‹ (JSON)
{
    "paper_type": "answered",
    "paper_type_confidence": 0.95,
    "paper_type_indicators": ["ì†ê¸€ì”¨ ë‹µì•ˆ ê°ì§€", "ì—¬ëŸ¬ ë¬¸í•­ì— ë‹µì•ˆ ì‘ì„±"],

    "grading_status": "fully_graded",
    "grading_confidence": 0.90,
    "grading_indicators": ["O/X í‘œì‹œ ë°œê²¬", "ì ìˆ˜ ê¸°ì¬ í™•ì¸"],

    "total_questions": 10,
    "question_details": [
        {
            "question_number": 1,
            "has_answer": true,
            "has_grading_mark": true,
            "grading_result": "correct",
            "confidence": 0.95
        },
        ...
    ],

    "summary": {
        "answered_count": 10,
        "correct_count": 7,
        "incorrect_count": 3,
        "blank_count": 0
    }
}
"""

    @classmethod
    def get_classification_prompt(cls) -> str:
        """ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        return cls.CLASSIFICATION_PROMPT
